{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xu Bai\\.conda\\envs\\tfenv\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Xu Bai\\.conda\\envs\\tfenv\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Xu Bai\\.conda\\envs\\tfenv\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_:\n",
      " [[0.969797861054287], [1.1634604857835003], [1.1942714411690643], [0.5384488448601839], [0.8632760602061649], [0.8339321949148727], [0.9280893354024469], [1.6879345369421652], [0.9036674505700479], [0.512956535191759], [0.7844252375973886], [1.299175094270699], [1.0919817282657285], [1.0880495166868347], [1.1734589741814216], [1.3098158421478576], [1.2387201482616108], [0.8289679938936613], [1.3550486329517144], [1.578666175492443], [0.7524305484165053], [0.7326318868381032], [1.2449966435046544], [0.788097599402105], [1.5577488607336392], [0.3889256997930456], [1.0277860551407527], [0.6104042277890978], [0.8594808823356304], [0.8810757430061307], [1.1456401959033111], [0.1907476486033659]]\n",
      "After 0 training steps, w1 is \n",
      "[[-0.8096241]\n",
      " [ 1.4855157]] \n",
      "\n",
      "After 500 training steps, w1 is \n",
      "[[-0.21934733]\n",
      " [ 1.6984866 ]] \n",
      "\n",
      "After 1000 training steps, w1 is \n",
      "[[0.0893971]\n",
      " [1.673225 ]] \n",
      "\n",
      "After 1500 training steps, w1 is \n",
      "[[0.28368822]\n",
      " [1.5853055 ]] \n",
      "\n",
      "After 2000 training steps, w1 is \n",
      "[[0.423243 ]\n",
      " [1.4906037]] \n",
      "\n",
      "After 2500 training steps, w1 is \n",
      "[[0.531055 ]\n",
      " [1.4053345]] \n",
      "\n",
      "After 3000 training steps, w1 is \n",
      "[[0.61725086]\n",
      " [1.332841  ]] \n",
      "\n",
      "After 3500 training steps, w1 is \n",
      "[[0.687201 ]\n",
      " [1.2725208]] \n",
      "\n",
      "After 4000 training steps, w1 is \n",
      "[[0.7443262]\n",
      " [1.2227542]] \n",
      "\n",
      "After 4500 training steps, w1 is \n",
      "[[0.7910986]\n",
      " [1.1818361]] \n",
      "\n",
      "After 5000 training steps, w1 is \n",
      "[[0.82943517]\n",
      " [1.1482395 ]] \n",
      "\n",
      "After 5500 training steps, w1 is \n",
      "[[0.860872 ]\n",
      " [1.1206709]] \n",
      "\n",
      "After 6000 training steps, w1 is \n",
      "[[0.88665503]\n",
      " [1.098054  ]] \n",
      "\n",
      "After 6500 training steps, w1 is \n",
      "[[0.90780276]\n",
      " [1.0795006 ]] \n",
      "\n",
      "After 7000 training steps, w1 is \n",
      "[[0.92514884]\n",
      " [1.0642821 ]] \n",
      "\n",
      "After 7500 training steps, w1 is \n",
      "[[0.93937725]\n",
      " [1.0517985 ]] \n",
      "\n",
      "After 8000 training steps, w1 is \n",
      "[[0.951048]\n",
      " [1.041559]] \n",
      "\n",
      "After 8500 training steps, w1 is \n",
      "[[0.96062106]\n",
      " [1.0331597 ]] \n",
      "\n",
      "After 9000 training steps, w1 is \n",
      "[[0.9684733]\n",
      " [1.0262702]] \n",
      "\n",
      "After 9500 training steps, w1 is \n",
      "[[0.97491425]\n",
      " [1.0206193 ]] \n",
      "\n",
      "After 10000 training steps, w1 is \n",
      "[[0.9801975]\n",
      " [1.0159837]] \n",
      "\n",
      "After 10500 training steps, w1 is \n",
      "[[0.9845312]\n",
      " [1.0121814]] \n",
      "\n",
      "After 11000 training steps, w1 is \n",
      "[[0.9880858]\n",
      " [1.0090628]] \n",
      "\n",
      "After 11500 training steps, w1 is \n",
      "[[0.99100184]\n",
      " [1.0065047 ]] \n",
      "\n",
      "After 12000 training steps, w1 is \n",
      "[[0.9933934]\n",
      " [1.0044063]] \n",
      "\n",
      "After 12500 training steps, w1 is \n",
      "[[0.9953551]\n",
      " [1.0026854]] \n",
      "\n",
      "After 13000 training steps, w1 is \n",
      "[[0.99696386]\n",
      " [1.0012728 ]] \n",
      "\n",
      "After 13500 training steps, w1 is \n",
      "[[0.9982835]\n",
      " [1.0001147]] \n",
      "\n",
      "After 14000 training steps, w1 is \n",
      "[[0.9993659]\n",
      " [0.999166 ]] \n",
      "\n",
      "After 14500 training steps, w1 is \n",
      "[[1.0002553 ]\n",
      " [0.99838644]] \n",
      "\n",
      "Final w1 is:  [[1.0009792]\n",
      " [0.9977485]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "SEED = 23455\n",
    "\n",
    "rdm = np.random.RandomState(seed=SEED)#生成[0,1)的随机数\n",
    "# 生成32行两列的输入特征x\n",
    "x = rdm.rand(32,2)\n",
    "# 生成噪声[0,1)/10 = [0,0.1)\n",
    "# rand()：生成0~1的随机数\n",
    "# y_是标准答案\n",
    "y_ = [[x1 + x2 + (rdm.rand() / 10.0 - 0.05)] for (x1,x2) in x]\n",
    "print(\"y_:\\n\",y_)\n",
    "x = tf.cast(x,dtype=tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random.normal([2,1],stddev=1,seed=1))\n",
    "epoch = 15000\n",
    "lr = 0.002\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 前向传播计算结果y\n",
    "        y = tf.matmul(x,w1)\n",
    "        loss_mse = tf.reduce_mean(tf.square(y_ -y))\n",
    "        \n",
    "    # 损失函数对待训练参数w1求偏导\n",
    "    grads = tape.gradient(loss_mse,w1)\n",
    "    # w1自更新\n",
    "    w1.assign_sub(lr * grads)\n",
    "    \n",
    "    if epoch % 500 == 0:\n",
    "        print(\"After %d training steps, w1 is \" % (epoch))\n",
    "        print(w1.numpy(),\"\\n\")\n",
    "print(\"Final w1 is: \",w1.numpy())\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
