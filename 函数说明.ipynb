{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预备知识\n",
    "\n",
    "tf.where(条件语句，真返回A，假返回B)\n",
    "\n",
    "    a = tf.constant([1,2,3,1,1,1])\n",
    "\n",
    "    b = tf.constant([0,1,3,4,5])\n",
    "\n",
    "\n",
    "若a>b，返回a`对应位置`的元素，否则返回b`对应位置`的元素\n",
    "\n",
    "greater比较对应元素\n",
    "\n",
    "    c = tf.where(tf.greater(a,b),a,b)\n",
    "    【out:】 tf.Tensor([1 2 3 4 5],shape=(5),dtype=int32)\n",
    "    \n",
    " ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.random.RandomState.rand(维度)\n",
    "返回一个[0,1)之间的随机数\n",
    "维度为空、返回张量\n",
    "\n",
    "    import numpy as np\n",
    "    rdm = np.random.RandomState(seed=1)#seed常数每次生成的随机数相同\n",
    "    a = rdm.rand() #返回一个随机标量\n",
    "    b = rdm.rand(2,3)#返回一个2行3列的随机数矩阵\n",
    "    print(\"a\",a)\n",
    "    print(\"b\",b)\n",
    "    【out:】\n",
    "    a:0.417022...........\n",
    "    b:[[7.20  .. ...],[.. .. ..]]\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    np.vstack()\n",
    "    将两个数组按垂直方向叠加\n",
    "    a = np.array([1,2,3])\n",
    "    b = np.array([4,5,6])\n",
    "    c = np.vstack((a,b))\n",
    "    print(\"c:\",c)\n",
    "    【out:】\n",
    "    c:\n",
    "    [[1 2 3],\n",
    "    [4 5 6]]\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    np.mgrid[] .ravel np.c_[]可以生成网格坐标点\n",
    "    \n",
    "    np.mgrid[起始值：结束值：步长，重复。。。] [)\n",
    "    返回若干组维度相同的等差数组\n",
    "    \n",
    "    \n",
    "    np.ravel() #把x变成一维数组\n",
    "    \n",
    "    np.c_[] 使返回的间隔数值点配对输出\n",
    "    np.c_[数组1，数组2，...]\n",
    "    \n",
    "    x,y = np.mgrid[1:3:1,2:4:0.5]\n",
    "    grid = np.c_[x.ravel(),y.ravel()]\n",
    "    print('x',x)\n",
    "    print('y',y)\n",
    "    print('grid:\\n',grid)\n",
    "    【out:】\n",
    "    x = [[1. 1. 1. 1.]\n",
    "        [2. 2. 2. 2.]]\n",
    "    y = [[2. 2.5 3. 3.5]\n",
    "        [2. 2.5 3. 3.5]]\n",
    "    grid:（竖着看）\n",
    "    [[1.2.]\n",
    "    [1. 2.5]\n",
    "    [1.3.]\n",
    "    [1.3.5]\n",
    "    [2.2.]\n",
    "    [2.2.5]\n",
    "    [2. 3.]\n",
    "    [2.3.5]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指数衰减学习率\n",
    "指数衰减学习率 = 初始学习率 * 学习率衰减率 ** （当前轮数 / 多少轮衰减一次）\n",
    "## sigmoid函数  -- 映射到 0~1\n",
    "特点：\n",
    "+ 易造成梯度消失\n",
    "+ 输出非0均值，收敛慢\n",
    "+ 幂运算复杂，训练时间长\n",
    "## tanh函数 0均值 \n",
    "## Relu -- 收敛速度远大于上面两者"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 激活函数\n",
    "对初学者的建议：\n",
    "+ 首选Relu激活函数\n",
    "+ 学习率设置较小值\n",
    "+ 输入特征标准化 、 *即让输入特征满足以0为均值，1为标准差的正态分布*\n",
    "+ 初始参数中心化，即让随机生成的参数满足以0为均值，$$\\sqrt{{2}\\over{当前层输入特征个数}}$$为标准差的正态分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数\n",
    "预测值y与已知答案y_之间的差距\n",
    "## 1.均方误差mse （Mean Squared Errot）\n",
    "MSE(y_,y) = $\\sum{(y-y_ )}^2 \\over n$\n",
    "\n",
    "    loss_mse = tf.reduce_mean(tf.square(y_ - y))\n",
    "*当使用均方误差mse、默认认为预测多了和预测少了损失是一样的，但是实际上，预测多了损失的可能是成本，预测少了损失的可能是利润。利润和成本往往不相等*\n",
    "## 2.自定义\n",
    "如预测酸奶销量、酸奶成本COST1元，利润PROFIT99元。预测少了损失利润99元，预测少了损失成本1元。所以希望生成的预测函数往多了预测\n",
    "loss_zdy = tf.reduce_sum(tf where :((tf.greater(y,y_),cost(y-y_),profit(y_-y)))\n",
    "\n",
    "## 3.交叉熵 ce (Cross Entropy)\n",
    "交叉熵表示两个概率分布之间的距离，交叉熵越大，两个概率分布越远。\n",
    "\n",
    "###  H(y_,y) = - $\\sum{y\\_ * ln y}$\n",
    "\n",
    "eg.二分类：\n",
    "已知答案y_ = (1,0)表示第一种情况发生的概率为1，第二种情况发生的概率0，\n",
    "\n",
    "预测y1 = (0.6,0.4) y2 = (0.8,0.2)哪个更接近标准答案y_?\n",
    "\n",
    "    答：H1((1,0),(0.6,0.4)) = 0.511\n",
    "    H2 = 0.223\n",
    "    H1 > H2\n",
    "    所以y2预测更准\n",
    "    \n",
    "    loss_ce1 = tf.losses.categorical_crossentropy([1,0],[0.6,0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softmax与交叉熵结合\n",
    " 输出先经过softmax函数，再计算y与y_的交叉熵损失函数\n",
    " `tf.nn.softmax_cross_entropy_with_logits(y_,y)`\n",
    " \n",
    "     y_ = np..array([[1 0 0],[0 1 0],[0 0 1],[1 0 0],[0 1 0]])\n",
    "     y = ...\n",
    "     y_pro = tf.nn.softnax(y)\n",
    "     # 分布计算\n",
    "     loss_ce1 = tf.losses.categorical_crossentropy(y_,y_pro)\n",
    "     \n",
    "     # 综合计算\n",
    "     loss_ce2 = tf.nn.softmax_cross_entropy_with_logits(y_,y)\n",
    "     计算结果loss_ce1 = loss_ce2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
