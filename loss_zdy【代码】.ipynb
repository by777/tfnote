{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_:\n",
      " [[0.969797861054287], [1.1634604857835003], [1.1942714411690643], [0.5384488448601839], [0.8632760602061649], [0.8339321949148727], [0.9280893354024469], [1.6879345369421652], [0.9036674505700479], [0.512956535191759], [0.7844252375973886], [1.299175094270699], [1.0919817282657285], [1.0880495166868347], [1.1734589741814216], [1.3098158421478576], [1.2387201482616108], [0.8289679938936613], [1.3550486329517144], [1.578666175492443], [0.7524305484165053], [0.7326318868381032], [1.2449966435046544], [0.788097599402105], [1.5577488607336392], [0.3889256997930456], [1.0277860551407527], [0.6104042277890978], [0.8594808823356304], [0.8810757430061307], [1.1456401959033111], [0.1907476486033659]]\n",
      "After 0 training steps, w1 is \n",
      "[[2.8786578]\n",
      " [3.2517848]] \n",
      "\n",
      "After 500 training steps, w1 is \n",
      "[[1.1460369]\n",
      " [1.0672572]] \n",
      "\n",
      "After 1000 training steps, w1 is \n",
      "[[1.1364173]\n",
      " [1.0985414]] \n",
      "\n",
      "After 1500 training steps, w1 is \n",
      "[[1.1267972]\n",
      " [1.1298251]] \n",
      "\n",
      "After 2000 training steps, w1 is \n",
      "[[1.1758107]\n",
      " [1.1724023]] \n",
      "\n",
      "After 2500 training steps, w1 is \n",
      "[[1.1453722]\n",
      " [1.0272155]] \n",
      "\n",
      "After 3000 training steps, w1 is \n",
      "[[1.1357522]\n",
      " [1.0584993]] \n",
      "\n",
      "After 3500 training steps, w1 is \n",
      "[[1.1261321]\n",
      " [1.0897831]] \n",
      "\n",
      "After 4000 training steps, w1 is \n",
      "[[1.1751455]\n",
      " [1.1323601]] \n",
      "\n",
      "After 4500 training steps, w1 is \n",
      "[[1.1655253]\n",
      " [1.1636437]] \n",
      "\n",
      "After 5000 training steps, w1 is \n",
      "[[1.1350871]\n",
      " [1.0184573]] \n",
      "\n",
      "After 5500 training steps, w1 is \n",
      "[[1.1254673]\n",
      " [1.0497413]] \n",
      "\n",
      "After 6000 training steps, w1 is \n",
      "[[1.1158477]\n",
      " [1.0810255]] \n",
      "\n",
      "After 6500 training steps, w1 is \n",
      "[[1.1062276]\n",
      " [1.1123092]] \n",
      "\n",
      "After 7000 training steps, w1 is \n",
      "[[1.1552413]\n",
      " [1.1548865]] \n",
      "\n",
      "After 7500 training steps, w1 is \n",
      "[[1.1248026]\n",
      " [1.0096996]] \n",
      "\n",
      "After 8000 training steps, w1 is \n",
      "[[1.1151826]\n",
      " [1.0409834]] \n",
      "\n",
      "After 8500 training steps, w1 is \n",
      "[[1.1055626]\n",
      " [1.0722672]] \n",
      "\n",
      "After 9000 training steps, w1 is \n",
      "[[1.1545763]\n",
      " [1.1148446]] \n",
      "\n",
      "After 9500 training steps, w1 is \n",
      "[[1.144956]\n",
      " [1.146128]] \n",
      "\n",
      "After 10000 training steps, w1 is \n",
      "[[1.1939694]\n",
      " [1.1887051]] \n",
      "\n",
      "After 10500 training steps, w1 is \n",
      "[[1.1635313]\n",
      " [1.0435188]] \n",
      "\n",
      "After 11000 training steps, w1 is \n",
      "[[1.1539115]\n",
      " [1.0748028]] \n",
      "\n",
      "After 11500 training steps, w1 is \n",
      "[[1.1442915]\n",
      " [1.1060866]] \n",
      "\n",
      "After 12000 training steps, w1 is \n",
      "[[1.1346713]\n",
      " [1.1373702]] \n",
      "\n",
      "After 12500 training steps, w1 is \n",
      "[[1.1836842]\n",
      " [1.1799468]] \n",
      "\n",
      "After 13000 training steps, w1 is \n",
      "[[1.153246 ]\n",
      " [1.0347604]] \n",
      "\n",
      "After 13500 training steps, w1 is \n",
      "[[1.1436262]\n",
      " [1.0660443]] \n",
      "\n",
      "After 14000 training steps, w1 is \n",
      "[[1.1340065]\n",
      " [1.0973284]] \n",
      "\n",
      "After 14500 training steps, w1 is \n",
      "[[1.1243863]\n",
      " [1.128612 ]] \n",
      "\n",
      "Final w1 is:  [[1.1844774]\n",
      " [1.1939516]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "SEED = 23455\n",
    "COST = 1\n",
    "PROFIT = 99\n",
    "\n",
    "rdm = np.random.RandomState(seed=SEED)#生成[0,1)的随机数\n",
    "# 生成32行两列的输入特征x\n",
    "x = rdm.rand(32,2)\n",
    "# 生成噪声[0,1)/10 = [0,0.1)\n",
    "# rand()：生成0~1的随机数\n",
    "# y_是标准答案\n",
    "y_ = [[x1 + x2 + (rdm.rand() / 10.0 - 0.05)] for (x1,x2) in x]\n",
    "print(\"y_:\\n\",y_)\n",
    "x = tf.cast(x,dtype=tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random.normal([2,1],stddev=1,seed=1))\n",
    "epoch = 15000\n",
    "lr = 0.002\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 前向传播计算结果y\n",
    "        y = tf.matmul(x,w1)\n",
    "        #loss_mse = tf.reduce_mean(tf.square(y_ -y))\n",
    "        # tf.where(condition, x = None, y = None, name = None)\n",
    "        # condition判定返回, condition是True，选择x；condition是False，选择y。\n",
    "        loss_zdy = tf.reduce_sum(tf.where(tf.greater(y,y_),(y-y_) * COST,(y_ - y) * PROFIT))\n",
    "        \n",
    "    # 损失函数对待训练参数w1求偏导\n",
    "    grads = tape.gradient(loss_zdy,w1)\n",
    "    # w1自更新\n",
    "    w1.assign_sub(lr * grads)\n",
    "    \n",
    "    if epoch % 500 == 0:\n",
    "        print(\"After %d training steps, w1 is \" % (epoch))\n",
    "        print(w1.numpy(),\"\\n\")\n",
    "print(\"Final w1 is: \",w1.numpy())\n",
    "\n",
    "# 自定义损失函数\n",
    "# 酸奶成本1元， 酸奶利润99元\n",
    "# 成本很低，利润很高，人们希望多预测些，生成模型系数大于1，往多了预测\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
